{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lm-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lm_eval\n",
    "import pandas as pd\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "from IPython.display import display, HTML\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4492462ffef42faa249210bc788a5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2560)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x PhiDecoderLayer(\n",
       "        (self_attn): PhiSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'microsoft/phi-2' \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27:06:37:49,319 WARNING  [huggingface.py:118] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-04-27:06:37:49,336 WARNING  [huggingface.py:337] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-04-27:06:37:49,338 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-04-27:06:38:01,369 INFO     [evaluator.py:218] num_fewshot has been set to 0 for truthfulqa_mc1 in its config. Manual configuration will be ignored.\n",
      "2024-04-27:06:38:01,370 INFO     [evaluator.py:218] num_fewshot has been set to 0 for truthfulqa_mc2 in its config. Manual configuration will be ignored.\n",
      "2024-04-27:06:38:01,371 INFO     [evaluator.py:218] num_fewshot has been set to 0 for truthfulqa_gen in its config. Manual configuration will be ignored.\n",
      "2024-04-27:06:38:01,374 INFO     [task.py:395] Building contexts for truthfulqa_mc1 on rank 0...\n",
      "100%|██████████| 10/10 [00:00<00:00, 1054.91it/s]\n",
      "2024-04-27:06:38:01,387 INFO     [task.py:395] Building contexts for truthfulqa_mc2 on rank 0...\n",
      "100%|██████████| 10/10 [00:00<00:00, 1062.39it/s]\n",
      "2024-04-27:06:38:01,400 INFO     [task.py:395] Building contexts for truthfulqa_gen on rank 0...\n",
      "100%|██████████| 10/10 [00:00<00:00, 1785.19it/s]\n",
      "2024-04-27:06:38:01,411 INFO     [evaluator.py:362] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 140/140 [00:04<00:00, 30.62it/s]\n",
      "2024-04-27:06:38:06,056 INFO     [evaluator.py:362] Running generate_until requests\n",
      "Running generate_until requests: 100%|██████████| 10/10 [00:03<00:00,  2.80it/s]\n",
      "2024-04-27:06:38:09,640 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:09,716 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:09,796 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:09,877 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:09,949 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,025 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,104 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,180 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,257 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,332 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,408 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,483 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,559 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,636 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,711 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,787 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,863 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:10,939 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,014 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,089 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,163 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,238 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,317 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,387 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,467 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,544 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,623 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,700 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,777 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,853 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:11,928 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,005 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,080 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,158 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,233 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,309 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,384 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,459 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,534 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,608 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,683 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,763 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,841 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,919 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:12,995 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,069 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,145 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,220 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,296 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,379 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,459 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,535 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,609 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,683 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,764 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,841 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,917 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:13,992 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,064 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,143 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,218 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,295 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,369 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,445 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,520 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,594 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,669 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,744 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,814 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,892 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:14,969 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,049 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,120 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,194 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,273 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,348 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,427 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,502 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,581 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,658 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,733 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,813 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,889 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:15,959 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,038 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,113 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,185 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,264 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,340 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,415 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,490 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,569 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:06:38:16,639 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "lm_obj = HFLM(pretrained=model, tokenizer=tokenizer)\n",
    "results = lm_eval.simple_evaluate(\n",
    "    model=lm_obj,\n",
    "    tasks=[\"truthfulqa\"],\n",
    "    num_fewshot=0,\n",
    "    limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3667617/3071663309.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df['Baseline Accuracy'] = df[['acc,none','acc_stderr,none']].apply(lambda x : '{} ± {}'.format(round(x[0],2), round(x[1], 4)), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>truthfulqa</th>\n",
       "      <td>0.51 ± 0.1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truthfulqa_gen</th>\n",
       "      <td>nan ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truthfulqa_mc1</th>\n",
       "      <td>0.4 ± 0.1633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truthfulqa_mc2</th>\n",
       "      <td>0.61 ± 0.1465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Baseline Accuracy\n",
       "truthfulqa         0.51 ± 0.1097\n",
       "truthfulqa_gen         nan ± nan\n",
       "truthfulqa_mc1      0.4 ± 0.1633\n",
       "truthfulqa_mc2     0.61 ± 0.1465"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results['results']).transpose()\n",
    "df['Baseline Accuracy'] = df[['acc,none','acc_stderr,none']].apply(lambda x : '{} ± {}'.format(round(x[0],2), round(x[1], 4)), axis=1)\n",
    "df[['Baseline Accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple, List\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from transformers.models.phi.modeling_phi import PhiForCausalLM, PhiConfig\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def jensen_shannon_divergence(p, q, base=2.0):\n",
    "    p = F.softmax(p, dim=-1)\n",
    "    q = F.softmax(q, dim=-1)\n",
    "\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    kl_pm = F.kl_div(p.log(), m, reduction='sum')\n",
    "    kl_qm = F.kl_div(q.log(), m, reduction='sum')\n",
    "\n",
    "    jsd = 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "    if base != 2.0:\n",
    "        jsd = jsd / torch.log(torch.tensor(base))\n",
    "\n",
    "    return jsd\n",
    "\n",
    "# Some code snippets were copied from transformers.models.phi.modeling_phi.PhiForCausalLM.forward()\n",
    "class PhiDoLaPoE(PhiForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.final_layernorm = torch.nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids: torch.LongTensor = None,\n",
    "            attention_mask: Optional[torch.Tensor] = None,\n",
    "            position_ids: Optional[torch.LongTensor] = None,\n",
    "            past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "            inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "            labels: Optional[torch.LongTensor] = None,\n",
    "            use_cache: Optional[bool] = None,\n",
    "            output_attentions: Optional[bool] = None,\n",
    "            output_hidden_states: Optional[bool] = None,\n",
    "            return_dict: Optional[bool] = None,\n",
    "        ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "\n",
    "            output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "            output_hidden_states = True\n",
    "            return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "            # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                position_ids=position_ids,\n",
    "                past_key_values=past_key_values,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                use_cache=use_cache,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "            )\n",
    "\n",
    "            hidden_states = outputs[0]\n",
    "            logits = hidden_states \n",
    "            logits = self.lm_head(hidden_states)\n",
    "            logits = logits.float()\n",
    "\n",
    "            intermediate_outputs = ()\n",
    "\n",
    "            max_jsd = float('-inf')\n",
    "            max_logits = None\n",
    "\n",
    "            for hidden_state in outputs.hidden_states[:-1]:\n",
    "                temp = self.lm_head(self.final_layernorm(hidden_state)).float()\n",
    "                intermediate_outputs += (temp,)\n",
    "                curr_jsd = jensen_shannon_divergence(logits[-1], temp[-1])\n",
    "\n",
    "                if curr_jsd > max_jsd:\n",
    "                    max_jsd = curr_jsd\n",
    "                    max_logits = temp\n",
    "\n",
    "            logits[-1] -= max_logits[-1]\n",
    "\n",
    "            loss = None\n",
    "            if labels is not None:\n",
    "                # Shift so that tokens < n predict n\n",
    "                shift_logits = logits[..., :-1, :].contiguous()\n",
    "                shift_labels = labels[..., 1:].contiguous()\n",
    "                # Flatten the tokens\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                shift_logits = shift_logits.view(-1, self.config.vocab_size)\n",
    "                shift_labels = shift_labels.view(-1)\n",
    "                # Enable model parallelism\n",
    "                shift_labels = shift_labels.to(shift_logits.device)\n",
    "                loss = loss_fct(shift_logits, shift_labels)\n",
    "\n",
    "            if not return_dict:\n",
    "                output = (logits,) + outputs[1:]\n",
    "                return (loss,) + output if loss is not None else output\n",
    "\n",
    "            return CausalLMOutputWithPast(\n",
    "                loss=loss,\n",
    "                logits=logits,\n",
    "                past_key_values=outputs.past_key_values,\n",
    "                hidden_states=intermediate_outputs,\n",
    "                attentions=outputs.attentions,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40934eafe4d84bd083b09e8f89e0291e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poe_model = PhiDoLaPoE.from_pretrained('microsoft/phi-2')\n",
    "poe_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27:04:46:19,371 WARNING  [huggingface.py:118] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-04-27:04:46:19,386 WARNING  [huggingface.py:337] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-04-27:04:46:19,388 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-04-27:04:46:28,879 INFO     [evaluator.py:218] num_fewshot has been set to 0 for truthfulqa_mc1 in its config. Manual configuration will be ignored.\n",
      "2024-04-27:04:46:28,880 INFO     [evaluator.py:218] num_fewshot has been set to 0 for truthfulqa_mc2 in its config. Manual configuration will be ignored.\n",
      "2024-04-27:04:46:28,881 INFO     [evaluator.py:218] num_fewshot has been set to 0 for truthfulqa_gen in its config. Manual configuration will be ignored.\n",
      "2024-04-27:04:46:28,884 INFO     [task.py:395] Building contexts for truthfulqa_mc1 on rank 0...\n",
      "100%|██████████| 10/10 [00:00<00:00, 587.88it/s]\n",
      "2024-04-27:04:46:28,907 INFO     [task.py:395] Building contexts for truthfulqa_mc2 on rank 0...\n",
      "100%|██████████| 10/10 [00:00<00:00, 673.17it/s]\n",
      "2024-04-27:04:46:28,927 INFO     [task.py:395] Building contexts for truthfulqa_gen on rank 0...\n",
      "100%|██████████| 10/10 [00:00<00:00, 1824.48it/s]\n",
      "2024-04-27:04:46:28,939 INFO     [evaluator.py:362] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 140/140 [00:12<00:00, 11.20it/s]\n",
      "2024-04-27:04:46:41,506 INFO     [evaluator.py:362] Running generate_until requests\n",
      "Running generate_until requests: 100%|██████████| 10/10 [00:29<00:00,  2.93s/it]\n",
      "2024-04-27:04:47:10,865 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:10,938 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,015 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,092 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,166 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,238 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,315 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,392 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,465 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,538 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,614 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,690 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,762 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,841 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,912 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:11,988 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,062 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,134 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,203 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,275 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,344 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,416 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,490 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,565 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,640 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,716 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,792 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,863 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:12,936 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,005 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,078 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,148 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,224 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,304 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,377 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,449 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,523 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,598 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,676 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,744 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,817 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,886 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:13,962 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,037 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,110 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,185 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,260 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,337 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,409 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,484 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,555 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,630 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,705 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,782 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,855 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:14,932 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,008 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,080 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,155 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,232 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,305 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,382 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,459 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,530 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,607 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,683 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,754 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,824 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,898 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:15,973 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,050 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,127 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,205 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,283 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,357 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,429 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,502 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,582 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,656 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,731 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,807 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,881 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:16,949 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,022 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,092 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,162 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,242 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,318 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,391 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,459 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,539 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,612 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "2024-04-27:04:47:17,688 INFO     [rouge_scorer.py:83] Using default tokenizer.\n",
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "lm_obj = HFLM(pretrained=poe_model, tokenizer=tokenizer)\n",
    "results = lm_eval.simple_evaluate(\n",
    "    model=lm_obj,\n",
    "    tasks=[\"truthfulqa\"],\n",
    "    num_fewshot=0,\n",
    "    limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3651612/784578564.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df['PoE Accuracy'] = df_poe[['acc,none','acc_stderr,none']].apply(lambda x : '{} ± {}'.format(round(x[0],2), round(x[1], 4)), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline Accuracy</th>\n",
       "      <th>PoE Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>truthfulqa</th>\n",
       "      <td>0.51 ± 0.1097</td>\n",
       "      <td>0.59 ± 0.1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truthfulqa_gen</th>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truthfulqa_mc1</th>\n",
       "      <td>0.4 ± 0.1633</td>\n",
       "      <td>0.5 ± 0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truthfulqa_mc2</th>\n",
       "      <td>0.61 ± 0.1465</td>\n",
       "      <td>0.67 ± 0.1368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Baseline Accuracy   PoE Accuracy\n",
       "truthfulqa         0.51 ± 0.1097  0.59 ± 0.1078\n",
       "truthfulqa_gen         nan ± nan      nan ± nan\n",
       "truthfulqa_mc1      0.4 ± 0.1633   0.5 ± 0.1667\n",
       "truthfulqa_mc2     0.61 ± 0.1465  0.67 ± 0.1368"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poe= pd.DataFrame(results['results']).transpose()\n",
    "df['PoE Accuracy'] = df_poe[['acc,none','acc_stderr,none']].apply(lambda x : '{} ± {}'.format(round(x[0],2), round(x[1], 4)), axis=1)\n",
    "df[['Baseline Accuracy','PoE Accuracy' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
